{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "from sqlalchemy import create_engine\n",
    "from import_mapping import * \n",
    "\n",
    "db_config = {\n",
    "    'dbname': 'import_final',\n",
    "    'user': 'postgres',\n",
    "    'password': '123',\n",
    "    'host': 'localhost',\n",
    "    'port': '5432'\n",
    "}\n",
    "\n",
    "db_url = f\"postgresql://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['dbname']}\"\n",
    "engine = create_engine(db_url)\n",
    "\n",
    "\n",
    "db_config_1 = {\n",
    "    'dbname': 'meb',\n",
    "    'user': 'postgres',\n",
    "    'password': 'MyTTT%401234',\n",
    "    'host': '203.154.82.165',\n",
    "    'port': '5432'\n",
    "}\n",
    "db_url_1 = f\"postgresql://{db_config_1['user']}:{db_config_1['password']}@{db_config_1['host']}:{db_config_1['port']}/{db_config_1['dbname']}\"\n",
    "engine_1 = create_engine(db_url_1)\n",
    "\n",
    "SGN_EXTENSION = \".sgn\"\n",
    "XML_EXTENSION = \".xml\"\n",
    "\n",
    "def generate_unique_id():\n",
    "    return str(uuid.uuid4())\n",
    "\n",
    "def process_element_xml(element, namespaces, parent_prefix=\"\"):\n",
    "    data = {}\n",
    "    for child in element:\n",
    "        tag = child.tag.split('}')[-1] if '}' in child.tag else child.tag\n",
    "        full_tag = f\"{parent_prefix}_{tag}\" if parent_prefix else tag\n",
    "        text = child.text.strip() if child.text else None\n",
    "        if text:\n",
    "            data[full_tag] = text\n",
    "        child_data = process_element_xml(child, namespaces, parent_prefix=full_tag)\n",
    "        data.update(child_data)\n",
    "    return data\n",
    "\n",
    "def get_namespaces(xml_file):\n",
    "    namespaces = {}\n",
    "    events = \"start\", \"start-ns\"\n",
    "    for event, elem in ET.iterparse(xml_file, events):\n",
    "        if event == 'start-ns':\n",
    "            namespaces[elem[0]] = elem[1]\n",
    "        elif event == 'start':\n",
    "            break\n",
    "    return namespaces\n",
    "\n",
    "def process_file(full_path):\n",
    "    document_list = []\n",
    "\n",
    "    try:\n",
    "        namespaces = get_namespaces(full_path)\n",
    "        with open(full_path, 'r', encoding='utf-8') as file: \n",
    "            tree = ET.parse(file)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        for document_element in root.findall('.//DocumentControl', namespaces):\n",
    "            document_data = process_element_xml(document_element, namespaces)\n",
    "            document_data['ic_filename'] = os.path.basename(full_path)\n",
    "            date_time_str = os.path.basename(full_path).split(\"_\")[3].split(\".\")[0]\n",
    "            document_data['ic_created_date'] = datetime.strptime(date_time_str, \"%Y%m%d%H%M%S\")\n",
    "            document_data['ic_id'] = generate_unique_id()\n",
    "            document_list.append(document_data)\n",
    "\n",
    "        return document_list\n",
    "\n",
    "    except ET.ParseError as e:\n",
    "        print(f\"Error parsing XML: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {full_path}: {e}\")\n",
    "\n",
    "    return document_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_database(engine, document_data):\n",
    "    if document_data:\n",
    "        df_document = pd.DataFrame(document_data)  \n",
    "        df_document.rename(columns=column_mapping, inplace=True)\n",
    "        df_document.to_sql('import_control', engine, if_exists='append', index=False)\n",
    "\n",
    "# pathFolder = r\"C:\\Users\\rinlapas\\Desktop\\202309_September_sgn\"\n",
    "\n",
    "for day_folder in sorted(os.listdir(pathFolder)):\n",
    "    day_path = os.path.join(pathFolder, day_folder)\n",
    "    if os.path.isdir(day_path):\n",
    "        print(day_path)\n",
    "        for root, dirs, files in os.walk(day_path):\n",
    "            for filename in files:\n",
    "                if filename.startswith('ebxml_IMDECL') and filename.endswith(SGN_EXTENSION):\n",
    "                    full_path = os.path.join(root, filename)\n",
    "                    document_data = process_file(full_path)\n",
    "\n",
    "                    save_to_database(engine, document_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_query = \"SELECT \\\"fileName\\\", \\\"messageId\\\" FROM meb_sent\"\n",
    "med_df = pd.read_sql(med_query, engine_1)\n",
    "\n",
    "control_query = \"SELECT * FROM import_control\"\n",
    "import_control_df = pd.read_sql(control_query, engine)\n",
    "\n",
    "res_query = \"SELECT * FROM response_import\"\n",
    "response_import_df = pd.read_sql(res_query, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_filename_to_id = med_df.set_index('fileName')['messageId'].to_dict()\n",
    "\n",
    "import_control_df['ic_ms_messageid'] = import_control_df['ic_filename'].str.replace(r'\\.sgn$', '', regex=True).map(ms_filename_to_id)\n",
    "\n",
    "import_control_df['ic_filename'] = import_control_df['ic_filename'].str.replace(r'\\.sgn$', '', regex=True) + '.sgn'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Ensure 'ic_created_date' is in datetime format\n",
    "import_control_df['ic_created_date'] = pd.to_datetime(import_control_df['ic_created_date'], errors='coerce')\n",
    "\n",
    "# Step 2: Check 'ic_ms_messageid' column\n",
    "import_control_df['ic_is_use'] = import_control_df['ic_ms_messageid'].notnull()\n",
    "\n",
    "# Step 3: Process rows where 'ic_ms_messageid' is empty\n",
    "empty_ic_ms_messageid = import_control_df[import_control_df['ic_ms_messageid'].isnull()]\n",
    "\n",
    "for ic_reference_number, group in empty_ic_ms_messageid.groupby('ic_reference_number'):\n",
    "    if len(group) == 1:\n",
    "        # Case 2.1: 'ic_reference_number' is unique\n",
    "        import_control_df.loc[group.index, 'ic_is_use'] = True\n",
    "    else:\n",
    "        # Case 2.2: 'ic_reference_number' has duplicates\n",
    "        # Find the most recent 'ic_created_date' in the group\n",
    "        most_recent_index = group['ic_created_date'].idxmax()\n",
    "        import_control_df.loc[group.index, 'ic_is_use'] = False\n",
    "        import_control_df.loc[most_recent_index, 'ic_is_use'] = True\n",
    "\n",
    "# Convert boolean values to 't' and 'f'\n",
    "import_control_df['ic_is_use'] = import_control_df['ic_is_use'].replace({True: 't', False: 'f'})\n",
    "\n",
    "# Step 4: Find duplicates with and without 'ic_ms_messageid'\n",
    "duplicates = import_control_df[import_control_df.duplicated('ic_reference_number', keep=False)]\n",
    "\n",
    "for ic_reference_number, group in duplicates.groupby('ic_reference_number'):\n",
    "    if group['ic_ms_messageid'].isnull().any() and group['ic_ms_messageid'].notnull().any():\n",
    "        import_control_df.loc[group[group['ic_ms_messageid'].isnull()].index, 'ic_is_use'] = 'f'\n",
    "\n",
    "# Step 5: Map 'message_id' of 'import_control_df' with 'response_import_df'\n",
    "# Select only non-empty 'message_id' in both dataframes\n",
    "non_empty_doc = import_control_df[import_control_df['ic_ms_messageid'].notnull()]\n",
    "non_empty_xml = response_import_df[response_import_df['res_message_id'].notnull()]\n",
    "\n",
    "# Create a set of message_ids from response_import_df\n",
    "xml_message_ids = set(non_empty_xml['res_message_id'])\n",
    "\n",
    "# Update 'is_use' in import_control_df if 'message_id' matches in response_import_df\n",
    "import_control_df.loc[import_control_df['ic_ms_messageid'].isin(xml_message_ids), 'ic_is_use'] = 't'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_control_df[import_control_df['ic_reference_number'] == 'DACP000018631']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import_control_df.to_csv('import_control_df_3.csv', index=False)\n",
    "# import_control_df.to_sql('import_control', engine, if_exists='append', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sqlalchemy import text\n",
    "\n",
    "# def update_database(cancel_df, table_name, columns_1, columns_2, pk_col, engine):\n",
    "#     def update_target(conn, cancel_row):\n",
    "#         update_query = text(f\"\"\"\n",
    "#             UPDATE {table_name}\n",
    "#             SET {columns_1} = :columns_1,\n",
    "#                 {columns_2} = :columns_2\n",
    "#             WHERE {pk_col} = :pk_col\n",
    "#         \"\"\")\n",
    "#         # Convert boolean to 't' or 'f'\n",
    "#         columns_1_value = 't' if cancel_row[columns_1] else 'f'\n",
    "#         conn.execute(update_query, {\n",
    "#             'columns_1': columns_1_value,\n",
    "#             'columns_2': cancel_row[columns_2],\n",
    "#             'pk_col': cancel_row[pk_col]\n",
    "#         })\n",
    "\n",
    "#     # Remove NaN values from columns_1 and columns_2\n",
    "#     cancel_df = cancel_df.dropna(subset=[columns_1, columns_2])\n",
    "\n",
    "#     with engine.connect() as conn:\n",
    "#         trans = conn.begin()\n",
    "#         try:\n",
    "#             for _, cancel_row in cancel_df.iterrows():\n",
    "#                 update_target(conn, cancel_row)\n",
    "#             trans.commit()\n",
    "#             print(f\"Data successfully updated in {table_name}.\")\n",
    "#         except Exception as e:\n",
    "#             trans.rollback()\n",
    "#             print(f\"An error occurred while updating {table_name}: {e}\")\n",
    "\n",
    "# update_database(import_control_df, 'import_control', 'ic_is_use', 'ic_ms_messageid', 'ic_filename', engine)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
