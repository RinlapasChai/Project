{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PostgreSQL connection successful\n",
      "PostgreSQL connection successful\n",
      "PostgreSQL connection successful\n",
      "SQL Server connection successful\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "from sqlalchemy import create_engine, update, Table, Column, Integer, String, MetaData, inspect,text\n",
    "import numpy as np\n",
    "import json\n",
    "import pyodbc\n",
    "\n",
    "# Database configuration\n",
    "db_config = {\n",
    "    'dbname': 'import_final',\n",
    "    'user': 'postgres',\n",
    "    'password': '123',\n",
    "    'host': 'localhost',\n",
    "    'port': '5432'\n",
    "}\n",
    "\n",
    "postgres_db_config_mo = {\n",
    "    'dbname': '67C_Monitoring',\n",
    "    'user': 'postgres',\n",
    "    'password': 'MyTTT%401234',\n",
    "    'host': '203.154.82.165',\n",
    "    'port': '5432'\n",
    "}\n",
    "\n",
    "postgres_db_config_med = {\n",
    "    'dbname': 'meb',\n",
    "    'user': 'postgres',\n",
    "    'password': 'MyTTT%401234',\n",
    "    'host': '203.154.82.165',\n",
    "    'port': '5432'\n",
    "}\n",
    "\n",
    "sql_server_config_server = {\n",
    "    'driver': '{SQL Server}',\n",
    "    'server': '203.154.82.165',\n",
    "    'database': 'response',\n",
    "    'user': 'sa',\n",
    "    'password': 'MyTTT@1234'\n",
    "}\n",
    "\n",
    "\n",
    "def setup_postgres_engine(db_config):\n",
    "    try:\n",
    "        db_url = f\"postgresql://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['dbname']}\"\n",
    "        engine = create_engine(db_url)\n",
    "        print(\"PostgreSQL connection successful\")\n",
    "        return engine\n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to PostgreSQL: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def setup_sql_server_connection(db_config):\n",
    "    try:\n",
    "        conn_str = (\n",
    "            f\"DRIVER={db_config['driver']};\"\n",
    "            f\"SERVER={db_config['server']};\"\n",
    "            f\"DATABASE={db_config['database']};\"\n",
    "            f\"UID={db_config['user']};\"\n",
    "            f\"PWD={db_config['password']};\"\n",
    "        )\n",
    "        conn = pyodbc.connect(conn_str)\n",
    "        print(\"SQL Server connection successful\")\n",
    "        return conn\n",
    "    except pyodbc.Error as e:\n",
    "        print(f\"Error connecting to SQL Server: {e}\")\n",
    "        return None\n",
    "        \n",
    "postgres_mybase = setup_postgres_engine(db_config)\n",
    "postgres_67C_Monitoring = setup_postgres_engine(postgres_db_config_mo)\n",
    "postgres_meb = setup_postgres_engine(postgres_db_config_med)\n",
    "sql_server_resp = setup_sql_server_connection(sql_server_config_server)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_query = \"SELECT * FROM import_control_2024\"\n",
    "import_control_df = pd.read_sql(control_query, postgres_mybase) \n",
    "\n",
    "control_query = \"\"\"SELECT * FROM response_import_2024_01_02\"\"\"\n",
    "response_import_df = pd.read_sql(control_query, postgres_mybase) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send : meb_send "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_query = \"\"\"SELECT \"fileName\", \"messageId\" FROM meb_sent\"\"\"\n",
    "med_df = pd.read_sql(med_query, postgres_meb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Mapping fileName\n",
    "ms_filename_to_id = med_df.set_index('fileName')['messageId'].to_dict()\n",
    "import_control_df['ic_ms_messageid'] = import_control_df['ic_filename'].str.replace(r'\\.sgn$', '', regex=True).map(ms_filename_to_id)\n",
    "import_control_df['ic_filename'] = import_control_df['ic_filename'].str.replace(r'\\.sgn$', '', regex=True) + '.sgn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Response : response, meb_inbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_sql_resp = \"\"\"SELECT \"FileName\", \"InboxId\" FROM response;\"\"\"\n",
    "df_sql_resp = pd.read_sql(query_sql_resp, sql_server_resp)\n",
    "df_sql_resp = df_sql_resp.astype(str)\n",
    "\n",
    "query_meb_inbox = \"\"\"SELECT \"id\", \"reftomessageid\", \"messagetimestamp\" FROM meb_inbox;\"\"\"\n",
    "df_meb_inbox = pd.read_sql(query_meb_inbox, postgres_meb)\n",
    "df_meb_inbox = df_meb_inbox.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping InboxId\n",
    "map_inbox_id = df_sql_resp.set_index('FileName')['InboxId'].to_dict()\n",
    "response_import_df['res_inbox_id'] = response_import_df['res_filename'].map(map_inbox_id)\n",
    "\n",
    "# Mapping reftomessageid\n",
    "map_message_id = df_meb_inbox.set_index('id')['reftomessageid'].to_dict()\n",
    "response_import_df['res_message_id'] = response_import_df['res_inbox_id'].map(map_message_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#หา FK ของ ic_id (res_ref_id)\n",
    "df_map = import_control_df.set_index('ic_reference_number')['ic_id'].to_dict()\n",
    "response_import_df['res_ref_id'] = response_import_df['res_ref_no'].map(df_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_import_df['res_data'] = response_import_df['res_data'].apply(json.dumps)\n",
    "response_import_df.to_sql('response_import', postgres_mybase, if_exists='append', index=False, chunksize=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declaration No. (PMTA,PMTR) : update ic_rs_id and ic_declaration_no "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT rs_id, rs_type, rs_message, rs_status_id, rs_status_priority FROM response_status WHERE rs_declaration_type = 'Import';\"\"\"\n",
    "df_response_status = pd.read_sql(query, postgres_67C_Monitoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_response_PAT = response_import_df[response_import_df['res_message_type'].isin(['PMTA', 'PMTR'])]\n",
    "df_response_status_PMT = df_response_status[df_response_status['rs_type'].isin(['PMTA', 'PMTR'])] \n",
    "df_response_status_PMT = df_response_status_PMT.loc[df_response_status_PMT.groupby(['rs_type', 'rs_message'])['rs_status_priority'].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_status = pd.merge(df_response_PAT, df_response_status_PMT, \n",
    "                        left_on=['res_message_type', 'res_message'], \n",
    "                        right_on=['rs_type', 'rs_message'],\n",
    "                        how='left') \n",
    "\n",
    "ic_rs_id_map = merged_status.groupby('res_ref_no')['rs_id'].first()\n",
    "ic_declaration_no_map = merged_status.groupby('res_ref_no')['res_declaration_number'].first()\n",
    "\n",
    "import_control_df['ic_rs_id'] = import_control_df['ic_reference_number'].map(ic_rs_id_map)\n",
    "import_control_df['ic_declaration_no'] = import_control_df['ic_reference_number'].map(ic_declaration_no_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cancel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_query = \"\"\" SELECT * FROM cancel WHERE cc_declaration_type = 'IMP'\n",
    "                AND cc_created_date BETWEEN '2024-01-01 00:00:00+00' AND '2024-02-29 23:59:59+00';\"\"\"\n",
    "df_cancel_import = pd.read_sql(res_query, postgres_mybase) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping fileName\n",
    "ms_filename_to_id = med_df.set_index('fileName')['messageId'].to_dict()\n",
    "df_cancel_import['cc_messageid'] = df_cancel_import['cc_filename'].str.replace(r'\\.sgn$', '', regex=True).map(ms_filename_to_id)\n",
    "df_cancel_import['cc_filename'] = df_cancel_import['cc_filename'].str.replace(r'\\.sgn$', '', regex=True) + '.sgn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Responce (XDCA,XCDR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_query = \"\"\"SELECT *,  res_data->>'DocumentNumber' AS DocumentNumber \n",
    "            FROM response_import \n",
    "            WHERE res_message_type = 'XCDA' OR res_message_type = 'XCDR';\"\"\" \n",
    "\n",
    "df_response_XCD = pd.read_sql(res_query, postgres_mybase) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping InboxId\n",
    "map_inbox_id = df_sql_resp.set_index('FileName')['InboxId'].to_dict()\n",
    "df_response_XCD['res_inbox_id'] = df_response_XCD['res_filename'].map(map_inbox_id)\n",
    "\n",
    "# Mapping reftomessageid\n",
    "map_message_id = df_meb_inbox.set_index('id')['reftomessageid'].to_dict()\n",
    "df_response_XCD['res_message_id'] = df_response_XCD['res_inbox_id'].map(map_message_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update : ic_is_cancel and ic_cancel_reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map df_cancel_import['cc_messageid'] กับ df_response_XCD['res_message_id']\n",
    "mapped_df = df_cancel_import[df_cancel_import['cc_messageid'].isin(df_response_XCD['res_message_id'])]\n",
    "\n",
    "# เอา mapped_df ที่ import_control_df['ic_declaration_no'] ไป map df_cancel_import['cc_document_number']\n",
    "for index, row in mapped_df.iterrows():\n",
    "    ic_declaration_no = row['cc_document_number']\n",
    "\n",
    "    # หาแถวที่ตรงกับ ic_declaration_no ใน import_control_df\n",
    "    import_control_df.loc[import_control_df['ic_declaration_no'] == ic_declaration_no, 'ic_is_cancel'] = 't'\n",
    "    import_control_df.loc[import_control_df['ic_declaration_no'] == ic_declaration_no, 'ic_cancel_reason'] = row['cc_cancel_reason']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declaration No. (IDCA,IDCA) : update ic_rs_id and ic_declaration_no "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_response_IDA = response_import_df[response_import_df['res_message_type'].isin(['IDCA', 'IDCR'])]\n",
    "df_response_status_IDC = df_response_status[df_response_status['rs_type'].isin(['IDCA', 'IDCR'])] \n",
    "df_response_status_IDC = df_response_status_IDC.loc[df_response_status_IDC.groupby(['rs_type', 'rs_message'])['rs_status_priority'].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_status = pd.merge(df_response_IDA, df_response_status_IDC, \n",
    "                        left_on=['res_message_type', 'res_message'], \n",
    "                        right_on=['rs_type', 'rs_message'],\n",
    "                        how='left') \n",
    "\n",
    "ic_rs_id_map = merged_status.groupby('res_ref_no')['rs_id'].first()\n",
    "ic_declaration_no_map = merged_status.groupby('res_ref_no')['res_declaration_number'].first()\n",
    "\n",
    "import_control_df['ic_rs_id'] = import_control_df['ic_reference_number'].map(ic_rs_id_map)\n",
    "import_control_df['ic_declaration_no'] = import_control_df['ic_reference_number'].map(ic_declaration_no_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update : ic_is_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# control_query = \"SELECT * FROM response_import\"\n",
    "# response_import_df = pd.read_sql(control_query, postgres_mybase) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Convert 'ic_created_date' to datetime and create 'ic_is_use' based on 'ic_ms_messageid' being not null\n",
    "import_control_df['ic_created_date'] = pd.to_datetime(import_control_df['ic_created_date'], errors='coerce')\n",
    "import_control_df['ic_is_use'] = import_control_df['ic_ms_messageid'].notnull()\n",
    "\n",
    "# Step 2: Handle rows with null 'ic_ms_messageid'\n",
    "empty_ic_ms_messageid = import_control_df[import_control_df['ic_ms_messageid'].isnull()]\n",
    "for ic_reference_number, group in empty_ic_ms_messageid.groupby('ic_reference_number'):\n",
    "    if len(group) == 1:\n",
    "        import_control_df.loc[group.index, 'ic_is_use'] = True\n",
    "    else:\n",
    "        most_recent_index = group['ic_created_date'].idxmax()\n",
    "        import_control_df.loc[group.index, 'ic_is_use'] = False\n",
    "        import_control_df.loc[most_recent_index, 'ic_is_use'] = True\n",
    "\n",
    "# Step 3: Convert boolean 'ic_is_use' to string 't' or 'f'\n",
    "import_control_df['ic_is_use'] = import_control_df['ic_is_use'].replace({True: 't', False: 'f'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 4: Handle duplicates and mismatches\n",
    "duplicates = import_control_df[import_control_df.duplicated('ic_reference_number', keep=False)]\n",
    "for ic_reference_number, group in duplicates.groupby('ic_reference_number'):\n",
    "    if group['ic_ms_messageid'].isnull().any() and group['ic_ms_messageid'].notnull().any():\n",
    "        import_control_df.loc[group[group['ic_ms_messageid'].isnull()].index, 'ic_is_use'] = 'f'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional Condition: Update 'ic_is_use' based on 'res_message_id' in 'response_import_df'\n",
    "response_idca = response_import_df[response_import_df['res_message_type'] == 'IDCA']\n",
    "response_message_ids_idca = set(response_idca['res_message_id'].values)\n",
    "\n",
    "duplicate_groups = duplicates.groupby('ic_reference_number')\n",
    "for ic_reference_number, group in duplicate_groups:\n",
    "    if len(group) > 1:  # Only consider duplicates\n",
    "        mask = group['ic_ms_messageid'].notnull() & ~group['ic_ms_messageid'].isin(response_message_ids_idca)\n",
    "        import_control_df.loc[group[mask].index, 'ic_is_use'] = 'f'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import_control_df.to_sql('import_control', postgres_mybase, if_exists='append', index=False, chunksize=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check : ic_is_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# กรณที่ ic_reference_number ไม่ซ้ำ \n",
    "import_control_df[import_control_df['ic_reference_number'] == 'DANU000105508']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# กรณีที่ ic_reference_number ซ้ำ มี ic_ms_messageid\n",
    "import_control_df[import_control_df['ic_reference_number'] == 'DJNU000016762']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# กรณีที่ ic_reference_number ซ้ำ ไม่มี ic_ms_messageid\n",
    "import_control_df[import_control_df['ic_reference_number'] == 'DMCO000025963']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# กรณีที่มี ic_reference_number ซ้ำและมี ic_ms_messageid และไม่มี ic_ms_messageid\n",
    "import_control_df[import_control_df['ic_reference_number'] == 'DAMK000019896']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ic_reference_number ซ้ำ ic_is_use ไม่มี t เลยสักตัว ไม่มี ic_ms_messageid เลยสักตัว\n",
    "duplicate_ref_numbers = import_control_df[import_control_df.duplicated('ic_reference_number', keep=False)]\n",
    "result = duplicate_ref_numbers.groupby('ic_reference_number').filter(\n",
    "    lambda x: ~x['ic_is_use'].eq('t').any()\n",
    ")\n",
    "\n",
    "unique_refs = result['ic_reference_number'].unique()\n",
    "unique_refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ic_reference_number ซ้ำ ic_ms_messageid จับได้ทุกตัว ic_is_use = 't ทุกตัว\n",
    "filtered_df = import_control_df[import_control_df['ic_is_use'] == 't']\n",
    "\n",
    "duplicate_entries = filtered_df[filtered_df['ic_reference_number'].duplicated(keep=False)]\n",
    "duplicate_entries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
